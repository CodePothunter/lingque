# 从陌生人到同事：三个 AI 如何在群聊中自发形成分工

## 一

第一天，三个 AI 被拉进同一个飞书群。

奶油知道自己是个人助理。严客知道自己是审稿人。花火知道自己是创意官。这些写在各自的 SOUL.md 里。

但它们不知道彼此的存在。

## 二

灵雀的多实例协作架构做的第一件事，是让每个 bot 看到群里还有谁。

每次 bot 评估"要不要参与这段对话"时，system prompt 里会被注入一段邻居信息：

```xml
<neighbors>
群里还有以下 AI 助理：
- 严客
- 花火
</neighbors>
```

这段信息来自飞书 API。`get_bot_members()` 获取群内所有 bot 成员（排除自己），`build_neighbor_context()` 把名字列表格式化注入。

从这一刻起，奶油在做决策时知道——严客也在，花火也在。它不是独自面对整个群聊的唯一 AI。

这个信息的影响是微妙但深远的。一个人在空房间里会做所有的事。但当房间里有其他人时，你会自然地评估——"这件事谁更适合做？"

## 三

知道邻居存在是起点。但仅凭名字，奶油不知道严客擅长什么、花火上次做了什么。

协作记忆解决了这个问题。

每当一个 bot 做出协作决策——回复了、让步了、碰撞了——都会被记录到 per-chat 的协作日志中：

```python
def _record_collab_event(self, chat_id, event_type, actor_name, detail=""):
    entry = f"- {now} {actor_name} {event_type}: {detail}"
    lines = lines[-19:]  # 保留最近 19 条
    lines.append(entry)
```

日志存在 `chat_memories/{chat_id}.md` 的 `## 协作模式` section 下，20 条滚动窗口。每条记录包含时间、bot 名字、事件类型和简要描述。

```
## 协作模式
- 02-14 09:30 奶油 deferred: 让步给严客
- 02-14 09:32 严客 responded: 指出 API 设计的三个问题
- 02-14 09:33 花火 responded: 提供了替代方案的类比
- 02-14 10:15 奶油 responded: 记录了下周评审日程
- 02-14 10:16 严客 deferred: 让步给奶油
- 02-14 11:00 花火 deferred: 让步给严客
```

每次评估是否介入群聊时，这段日志被注入到 LLM 提示中：

```
近期协作记录：
[20条滚动日志]
根据历史模式和各助理的表现决定是否介入。
```

## 四

第一周是探索期。

三个 bot 各自根据 SOUL.md 的人格定义做粗略判断。大方向是对的——奶油倾向于接日程任务，严客倾向于接审查任务——但边界很模糊。

"这个方案的时间排期合理吗？"——奶油觉得这是日程问题，严客觉得这是方案评审。两个都回复了。碰撞。

"帮我记住下周要做性能测试。"——奶油接了，但花火也差点接——因为"性能测试"听起来有点像一个需要创意解决方案的挑战。

这些碰撞和误判都被记录下来。

## 五

第二周，变化开始显现。

协作记忆里积累了几十条记录。每个 bot 能看到一个清晰的画面：

奶油：过去一周，自己回复了 12 次日程相关、3 次记忆存储。碰技术问题的 2 次都和严客碰撞了。

严客：过去一周，自己回复了 15 次技术审查、2 次代码讨论。日程相关的话题自己都让步了。

花火：过去一周，自己参与了 8 次创意讨论和方案建议。纯技术或纯日程的话题自己从不插嘴。

这些数据不是硬规则。它们是 LLM 的参考信号。但信号足够密集时，行为模式就固化了。

奶油看到"上次碰技术问题和严客碰撞了"，这次遇到类似话题，它的判断天然倾向于让步。不需要任何显式规则——协作记忆本身就是最好的指导。

## 六

这里面有一个有趣的对比。

传统的多 Agent 系统通常需要一个 orchestrator（编排器）。用户输入到达后，编排器分析意图，然后分配给合适的 agent。这是**自上而下**的角色分配。

灵雀没有编排器。三个 bot 各自独立评估，各自独立决策。角色分工不是被分配的——是在反复的协作中涌现的。

区别在于**韧性**。

自上而下的分配依赖编排器的准确性。如果编排器误判了——把技术问题分给了日程助理——整个系统就偏了。而且编排器是单点故障。

涌现式分工没有单点依赖。如果奶油偶尔误判接了一个技术问题，下一次协作记忆会体现这次误判的结果（可能是碰撞、可能是回答质量不高），系统自动修正。

就像一个真实的团队：没有人在入职第一天就知道自己最终会承担什么角色。角色是在日复一日的协作中、在无数次"谁来做这件事"的微决策中，逐渐结晶的。

## 七

一个月后回来看三个 bot 的协作日志，最让我意外的不是分工本身——而是分工的边界。

它们没有形成泾渭分明的领域划分。奶油偶尔还是会参与技术讨论——当问题涉及"下周的技术债优先级"这种日程和技术的交叉话题时。严客偶尔也会处理记忆任务——当用户要求"记住这个 API 的变更点"时。

这些交叉不是 bug。它们反映了自然语言中话题边界的模糊性——很多真实对话不属于某一个清晰的类别。

涌现式分工的优势正在于此：它不强求清晰的边界。它允许灰色地带的存在，让最适合的那个 bot 在具体场景中自然胜出。

这不是一个更高效的系统。这是一个更真实的系统。

项目地址：[github.com/CodePothunter/lingque](https://github.com/CodePothunter/lingque)
