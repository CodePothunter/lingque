# 你的 AI 为什么总忘事？因为它不会数 token

你有没有这种经历：

跟 AI 聊了半小时，突然问它"我刚才说的那个方案你还记得吗"——它一脸茫然。

问题出在哪？**它数消息条数，不数信息量。**

---

## 旧做法有多蠢

大多数 AI 对话管理的逻辑是：超过 50 条消息，压缩一次，保留最后 10 条。

但是——

你发一条"好的" = 1 条消息。
你发一段 2000 字的技术方案 = 1 条消息。

在旧系统里，它们权重一样。

结果就是：10 条"嗯嗯好的收到"把你的完整讨论挤出了上下文窗口。

---

## 灵雀的做法：按 token 算

灵雀重写了整个会话管理，改用 token 预算制：

- **总预算 40,000 tokens**（Claude 上下文窗口 200k，预留大量空间给 system prompt 和输出）
- **30,000 tokens 触发压缩**
- **压缩后保留 15,000 tokens 的近期消息**

而且它会区分中文和英文——中文 1 个字 ≈ 1.5 tokens，英文 1 个字符 ≈ 0.3 tokens。混合内容加权计算。

---

## system prompt 也分优先级

不只是聊天记录——AI 的"自我认知"也有预算分配：

```
灵魂文件 SOUL.md → 3000 tokens（最高优先级，永远完整）
长期记忆 MEMORY.md → 4000 tokens（超了就按段落截断）
对话日志 → 2000 tokens
能力清单 → 2000 tokens
```

**灵魂永远不会被截断。** 记忆可以，但截断时保留所有标题结构，优先丢旧内容保留新内容。

---

## 还有个细节：工具调用也记住了

以前 AI 帮你查了个汇率，转头就忘。

现在工具调用（查汇率、创日历、记事情）全部写进会话历史。压缩的时候摘要会包含"之前查过汇率 1:0.137"这种关键信息。

你问"刚才查的汇率是多少"——它真的能答上来。

---

## 最后

记忆管理的本质不是"记住更多"——是"在有限的空间里，记住最重要的"。

一个会数 token 的 AI，才是一个不忘事的 AI。

GitHub：[灵雀 LingQue](https://github.com/CodePothunter/lingque)

---

你的 AI 助理记得住你的生日吗？评论区说 👇

#AI记忆 #飞书 #AI助理 #token管理 #开源 #灵雀 #LLM
