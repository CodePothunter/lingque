# AI 自己改自己的代码！开源项目 LingQue 实现「代码级自我进化」，改完还能自动回滚

**新智源报道**

> 【导读】一个开源 AI 助手框架实现了完整的自我改进闭环：每小时自动反思、分析自身源代码、提交 Git commit、验证安全性。改崩了？自动 `git reset --hard` 回滚，还会把失败教训记下来，下次避开同样的坑。

---

## 不是「自动写代码」，是「自己改自己」

2024 年以来，AI 编程助手层出不穷——Cursor、Copilot、Devin……但它们都是在帮**人类**写代码。有没有一种 AI，能**修改自己的源代码**让自己变得更好？

一个名为 **LingQue（灵雀）** 的开源项目给出了一个工程化的答案。

与其说它是一个 AI 助手，不如说它是**一个会自我迭代的 AI 框架**——在运行过程中，它会自主分析自己的代码质量、发现问题、编写修复、提交 commit、验证是否安全，整个流程无需人类干预。

**最关键的是：如果改挂了，它会自动回滚。**

---

## 三层循环，从「对话反思」到「代码进化」

LingQue 的自我改进不是一个简单的"让 LLM 写代码"功能，而是由三个时间尺度的循环组成的完整体系。

### 第一层：对话级反思（每次回复后）

每次回复用户消息后，LingQue 会花 150 个 token 做一次快速自我评估：

```
[质量:中] 回答了用户的问题但缺少具体示例
[好奇:分布式锁的 Redis 实现细节]
```

**这不是做样子。** 这些评估会被积累到日志中，质量评分用来发现回复质量的下滑趋势，好奇心话题则被收集起来，等待下一个"空闲时间段"去深入探索。

### 第二层：心跳级自主行动（每 3600 秒）

这是核心机制。LingQue 内置了一个**心跳调度器**，每小时触发一次（仅在 8:00–23:00 活跃），每次心跳会启动一个完整的自主行动周期：

**信号收集阶段**——聚合过去一段时间的所有"线索"：

| 信号源 | 内容 |
|--------|------|
| 好奇心信号 | 最近 20 条从反思中提取的话题 |
| 反思日志 | 今日最近 15 条回复质量评估 |
| 工具统计 | 各工具的成功率、失败原因、调用频次 |
| 进化日志 | EVOLUTION.md 中的待办改进和失败教训 |
| Git 历史 | 最近 10 条 commit（含进化提交） |
| 源码结构 | 完整的目录树 + 每个文件的大小 |

**LLM 决策阶段**——所有信号注入 prompt，LLM 自主选择行动方向：

- **方向 A：探索学习** —— 用搜索引擎研究一个感兴趣的话题，把收获写入 CURIOSITY.md，甚至可以创建新的自定义工具
- **方向 B：自我进化** —— 分析框架源代码、找到改进点、动手修改

优先级规则：如果 EVOLUTION.md 里有待办改进且今日还有改进配额（默认 3 次/天），优先选择进化。配额用完了只能探索。

### 第三层：启动级安全验证（每次重启时）

每次进化前，系统会用 `git rev-parse HEAD` 保存一个 checkpoint。下次启动时：

```
有 checkpoint？
├─ 上次是正常关闭 → 进化成功，清除 checkpoint
└─ 上次是异常关闭 → 跑健康检查
    ├─ 4 个核心模块 import 全部通过 → OK
    └─ 任一失败 → git reset --hard 到 checkpoint
                  把失败记录写入 EVOLUTION.md
```

**四个健康检查点**涵盖了系统的全部核心：`AssistantGateway`、`MessageRouter`、`MemoryManager`、`SessionManager`。每个在独立子进程中执行，15 秒超时。只要有一个挂了，整个进化就会被回滚。

---

## 一个完整的进化实例

让我们跟踪一个真实的进化过程：

**Step 1：信号积累**（持续数小时）

LingQue 在多次对话反思中注意到 `web_search` 工具的失败率偏高。工具统计也印证了这一点：过去 24 小时成功率仅 68%，主要错误是超时。

**Step 2：心跳触发**（某个整点）

自主行动周期启动，LLM 看到了所有上下文：

```
## 工具使用统计
web_search: 调用 31 次, 成功 21 次 (67.7%), 最近错误: TimeoutError
...
## 今日剩余代码改进次数: 2
```

LLM 决定：改进 `web_search` 的超时处理。

**Step 3：诊断**

LLM 用 `read_file` 读取 `router/web_tools.py`，发现超时写死了 10 秒，没有重试机制。

**Step 4：保存 checkpoint**

系统自动执行 `git rev-parse HEAD`，保存当前 commit hash `a1b2c3d`。

**Step 5：执行修改**

LLM 通过 `run_claude_code` 在源码仓库中修改代码：
- 将超时从 10 秒改为 30 秒
- 增加一次自动重试
- commit 信息：`🧬【进化】：增加 web_search 超时和重试机制`

**Step 6：验证**

系统执行 `python -c 'from lq.gateway import AssistantGateway'`——通过。

**Step 7：记录**

EVOLUTION.md 更新：

```markdown
## 已完成

### 2026-02-19 — web_search 超时和重试优化
- 修改文件: router/web_tools.py
- 将超时从 10s 增加到 30s，增加 1 次重试
- 改进原因: 工具统计显示成功率仅 68%，主因超时
- commit: e4f5g6h
```

**Step 8：下次重启生效**

重启时健康检查通过 → checkpoint 清除 → 进化成功。

如果 Step 6 验证失败呢？系统会 `git checkout .` 回滚当次修改。如果甚至来不及验证就崩溃了呢？下次启动的第三层安全验证会兜底。

---

## 不会无限膨胀的进化日志

随着时间推移，EVOLUTION.md 的已完成记录会越来越多。LingQue 引入了**日志压缩机制**：

- 已完成超过 **10 条** → 触发压缩，LLM 摘要旧条目，保留最近 5 条
- 失败记录超过 **5 条** → 触发压缩，LLM 提炼教训，保留最近 3 条

压缩后的样子：

```markdown
📦 历史改进归档（2026-01 ~ 2026-02）
- 优化了 session 压缩的 token 计算，减少 15% 上下文占用（`a1b2c3d`）
- 增强了群聊 buffer 的超时处理，修复消息丢失问题（`e4f5g6h`）
- 为 web_search 增加了 30s 超时和重试机制（`i7j8k9l`）
```

关键 commit hash 被保留了——LLM 随时可以通过 `git show <hash>` 回溯查看每次进化的完整 diff。

**失败教训同样不会丢失：**

```markdown
⚠️ 历史失败教训（2026-01 ~ 2026-02）
- 修改 import 结构时容易引发循环导入，需要先画依赖图
- 改动 session.py 的序列化格式时必须考虑旧数据兼容性
- 并发修改 gateway.py 的事件循环时风险极高，建议拆小改
```

这意味着 LingQue 不仅能从成功中积累经验，还能**从失败中学习**。

---

## 安全边界：不是「AI 失控」

可能有人会问：让 AI 改自己的代码，安全吗？

LingQue 设计了多层防护：

**频次约束**
- 每日最多 3 次代码进化（可配置）
- 自主行为日预算上限 $3.0（好奇心 $1 + 进化 $2）
- 仅在 8:00–23:00 活跃，深夜不搞事

**范围约束**
- 只改框架代码，不改实例配置和用户数据
- 向后兼容，不删已有功能
- 敏感操作需先通知主人

**技术安全网**
- 进化前 Git checkpoint，崩溃自动回滚
- 修改后立即 import 验证
- 自定义工具 AST 静态分析，禁止 `subprocess`、`shutil`、`ctypes` 等危险模块

**可追溯性**
- 进化 commit 统一前缀 `🧬【进化】：`，在 git log 里一目了然
- 每次进化详细记录到 EVOLUTION.md
- 失败教训永久保留

---

## 技术参数一览

| 参数 | 值 | 说明 |
|------|-----|------|
| 心跳间隔 | 3600 秒 | 自主行动触发频率 |
| 活跃时段 | 08:00–23:00 CST | 非活跃时段不触发 |
| 反思 token 上限 | 150 | 每次回复后的自我评估 |
| 好奇心信号采集 | 最近 20 条 | 去重后注入决策 prompt |
| 进化每日上限 | 3 次 | 防止过度修改 |
| 好奇心预算 | $1.0/天 | 探索学习的 API 费用上限 |
| 进化预算 | $2.0/天 | 代码改进的 API 费用上限 |
| 健康检查模块 | 4 个 | 每个 15 秒超时 |
| 已完成压缩阈值 | > 10 条 | 保留最近 5 条 |
| 失败压缩阈值 | > 5 条 | 保留最近 3 条 |

---

## 写在最后

LingQue 的自我进化框架证明了一件事：**AI 的自我改进是可以工程化的**。

不是什么神秘的 AGI 突破，不是不可控的 AI 失控。它就是一个有预算、有频次限制、有 Git 回滚、有健康检查的**自动化代码改进管道**。

但这个方向的潜力是巨大的。想象一下：一个 AI 助手运行了半年，它的工具成功率从 70% 提升到了 95%，它的超时处理越来越鲁棒，它甚至根据用户的使用模式给自己加上了新功能——而这一切都是它自己完成的，每一步都可以在 git log 里追溯。

**这不是科幻，这是已经在运行的代码。**

---

*本文基于 LingQue 开源代码分析。项目正在活跃开发中，机制细节可能随版本迭代变化。*

*参考阅读：Reflexion: Language Agents with Verbal Reinforcement Learning (NeurIPS 2023)*
