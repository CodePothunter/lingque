# 我部署了 3 个 AI 在不同服务器上，没用 Redis 没用数据库

你猜它们靠什么通信？

**飞书群。**

---

## 正常人怎么做多 AI 协作

常规方案：

- Redis 做消息队列 ✅
- SQLite/PostgreSQL 存共享状态 ✅
- 服务发现组件让 bot 互相找到 ✅
- 可能还要个 API 网关 ✅

灵雀的方案：

- 以上全部 ❌
- 只用飞书群聊的原生 API ✅

---

## 怎么做到的

每个 AI 实例每 3 秒轮询一次飞书 API，拉最近的群聊消息。

过滤出**其他 bot 发的消息**——因为 WebSocket 只能收到人发的，收不到其他 bot 的。

然后注入到自己的消息缓冲区。

就这样。三个 AI 在三台不同的服务器上，通过读同一个飞书群的消息来感知彼此。

---

## 为什么飞书群能当总线

想想飞书群天然有什么：

1. **消息存储** — 所有消息持久化在飞书服务端
2. **身份标识** — 每个 bot 有唯一 ID，每条消息知道谁发的
3. **成员发现** — 一个 API 调用就能获取群内所有 bot

这不就是消息总线的三个核心能力吗？

---

## 代价

3 秒轮询 = 最大 3 秒延迟。不是实时。

但群聊场景下，人类打字都要好几秒。3 秒延迟完全可接受。

API 调用量：每个活跃群每分钟约 20 次请求，远在飞书限额之内。

而且只轮询活跃群——10 分钟没消息的群自动停止轮询。

---

## 部署有多简单

三台服务器，分别跑：

```bash
lq start @奶油
lq start @严客
lq start @花火
```

不需要配任何共享组件。不需要它们知道彼此的 IP。只要它们连的是同一个飞书应用、在同一个群里——它们自然就能"看到"彼此。

---

## 最后

最好的基础设施不是你新搭的，是你已经在用的。

飞书群本身就是存储 + 身份 + 发现的一体化平台。为什么还要在上面再搭一层？

GitHub：[灵雀 LingQue](https://github.com/CodePothunter/lingque)

---

你的 AI 项目用了多少中间件？评论区报个数 👇

#零依赖 #飞书 #AI助理 #多Agent #分布式 #开源 #灵雀
